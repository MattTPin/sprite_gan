{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, utils, models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activate GPU if one is avalible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"\"\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/pokemon-bw-28/pokemon_sprites_bw_28x28\"\n",
    "IMAGE_SIZE = 28\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "     transforms.Grayscale(num_output_channels=1),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5,), (0.5,)\n",
    "    )\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = datasets.ImageFolder(root=DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(10, 8)); plt.axis(\"off\"); plt.title(\"Sample Training Images\")\n",
    "plt.imshow(np.transpose(utils.make_grid(sample_batch[0], padding=1, normalize=True),(1, 2, 0)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "train_set_ex = torchvision.datasets.MNIST(\n",
    "    root=\".\", train=True, download=True, transform=transform\n",
    ")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader_ex = torch.utils.data.DataLoader(\n",
    "    train_set_ex, batch_size=batch_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test iterator\n",
    "real_samples_ex, mnist_labels_ex = next(iter(train_loader_ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_samples, mnist_labels = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare/ Deploy GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.model(x)\n",
    "        output = output.view(x.size(0), 1, 28, 28)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test generator\n",
    "latent_space_samples = torch.randn(batch_size, 100).to(device=device)\n",
    "generated_samples = generator(latent_space_samples)\n",
    "generated_list_img = generated_samples.cpu().detach()\n",
    "plt.imshow(generated_list_img[0].reshape(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00005\n",
    "num_epochs = 10000\n",
    "loss_function = nn.BCELoss()\n",
    "\n",
    "optimizer_discriminator = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "optimizer_generator = torch.optim.Adam(generator.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SIZE = 100\n",
    "fixed_noise = torch.randn(batch_size, LATENT_SIZE, 1, 1, device=device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list = []\n",
    "gen_losses = []\n",
    "dis_losses = []\n",
    "ITERS = 0\n",
    "\n",
    "print_n = 0\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for n, (real_samples, labels) in enumerate(train_loader):\n",
    "        # Data for training the discriminator\n",
    "        real_samples = real_samples.to(device=device)\n",
    "        real_samples_labels = torch.ones((batch_size, 1)).to(\n",
    "            device=device\n",
    "        )\n",
    "        latent_space_samples = torch.randn((batch_size, 100)).to(\n",
    "            device=device\n",
    "        )\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        generated_samples_labels = torch.zeros((batch_size, 1)).to(\n",
    "            device=device\n",
    "        )\n",
    "        all_samples = torch.cat((real_samples, generated_samples))\n",
    "        all_samples_labels = torch.cat(\n",
    "            (real_samples_labels, generated_samples_labels)\n",
    "        )\n",
    "\n",
    "        # Training the discriminator\n",
    "        discriminator.zero_grad()\n",
    "        output_discriminator = discriminator(all_samples)\n",
    "        loss_discriminator = loss_function(\n",
    "            output_discriminator, all_samples_labels\n",
    "        )\n",
    "        loss_discriminator.backward()\n",
    "        optimizer_discriminator.step()\n",
    "\n",
    "        # Data for training the generator\n",
    "        latent_space_samples = torch.randn((batch_size, 100)).to(\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # Training the generator\n",
    "        generator.zero_grad()\n",
    "        generated_samples = generator(latent_space_samples)\n",
    "        output_discriminator_generated = discriminator(generated_samples)\n",
    "        loss_generator = loss_function(\n",
    "            output_discriminator_generated, real_samples_labels\n",
    "        )\n",
    "        loss_generator.backward()\n",
    "        optimizer_generator.step()\n",
    "        \n",
    "        if n == batch_size - 1:\n",
    "            print_n += 1 \n",
    "\n",
    "        if print_n == 10:\n",
    "            generated_list_img = generated_samples.cpu().detach()\n",
    "            img_list.append(utils.make_grid(generated_list_img, nrow=4, normalize=True))\n",
    "        \n",
    "        # Show loss\n",
    "        if print_n == 10:\n",
    "            print_n = 0\n",
    "            print(f\"Epoch: {epoch} Loss D.: {loss_discriminator}\")\n",
    "            print(f\"Epoch: {epoch} Loss G.: {loss_generator}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_space_samples = torch.randn(batch_size, 100).to(device=device)\n",
    "generated_samples = generator(latent_space_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine/Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = generated_samples.cpu().detach()\n",
    "for i in range(32):\n",
    "    ax = plt.subplot(4, 8, i + 1)\n",
    "    plt.imshow(generated_samples[i].reshape(28, 28), cmap=\"gray\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    #plt.savefig('pokemon_1000_results.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = generated_samples.cpu().detach()\n",
    "plt.imshow(generated_samples[15].reshape(28, 28), cmap=\"gray\")\n",
    "#plt.savefig('pokemon_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples = generated_samples.cpu().detach()\n",
    "plt.imshow(generated_samples[30].reshape(28, 28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in generated_samples]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "ani.save('pokemon_1000.gif', writer='imagemagick', fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save('pokemon_1000.gif', writer='imagemagick', fps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml()) # run this in a new cell to produce the below animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(ani.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
